{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87880c0e",
   "metadata": {},
   "source": [
    "### Use this cell to make installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea66d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pocketsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431f117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7022 sha256=400fd507667e48c8b872c437b2f87f19d052e41dd5c89e39a3003733a7371688\n",
      "  Stored in directory: /Users/muddassirkhalidi/Library/Caches/pip/wheels/50/98/42/62753a9e1fb97579a0ce2f84f7db4c21c09d03bb2091e6cef4\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d246e374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from openai-whisper) (0.57.0)\n",
      "Requirement already satisfied: numpy in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from openai-whisper) (1.24.3)\n",
      "Requirement already satisfied: torch in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from openai-whisper) (2.2.2)\n",
      "Requirement already satisfied: tqdm in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from openai-whisper) (8.12.0)\n",
      "Requirement already satisfied: tiktoken in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from openai-whisper) (0.7.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from numba->openai-whisper) (0.40.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from jinja2->torch->openai-whisper) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/muddassirkhalidi/anaconda3/lib/python3.11/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801342 sha256=e572deefa8e5c467b62f31872094e85f1f4408799ecb1b0bbb3ff3a2ee6c6dbb\n",
      "  Stored in directory: /Users/muddassirkhalidi/Library/Caches/pip/wheels/55/5d/42/c296ab046d52caa0adc0e3f159e98f011b3994a022d6282105\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: openai-whisper\n",
      "Successfully installed openai-whisper-20231117\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107466e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c6dd29",
   "metadata": {},
   "source": [
    "### Use this cell to import any libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb138f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "from openai import OpenAI #Only for testing purposes\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4c9d7",
   "metadata": {},
   "source": [
    "### Converting text to speech using TTS from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afc247e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting for ambience...\n",
      "Listening...\n",
      "Recognizing...\n",
      "Recognized\n",
      "hey are you feeling today\n",
      "Something printed\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "with open('test_file.txt') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "response = client.audio.speech.create(\n",
    "    model = \"tts-1\",\n",
    "    voice = \"alloy\",\n",
    "    input = text,\n",
    ")\n",
    "\n",
    "response.stream_to_file(\"test_speech.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50624918",
   "metadata": {},
   "source": [
    "### Converting Speech to Text using `google`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f17af1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zb/2519d8rs78v6ckcybj75fnl80000gp/T/ipykernel_1326/3712233357.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(\"test_speech.mp3\")\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "#Implementation using google\n",
    "def speech_to_text():\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print('Adjusting for ambience...')\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            \n",
    "            print('Listening...')\n",
    "            audio = recognizer.listen(source, phrase_time_limit = 180)\n",
    "            \n",
    "            print('Recognizing...')\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print('Recognized')\n",
    "            print(text)\n",
    "            print('Something printed')\n",
    "    except sr.RequestError as e:\n",
    "        print(e)\n",
    "    except sr.UnknownValueError as e:\n",
    "            print(e)\n",
    "\n",
    "speech_to_text()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31fadae",
   "metadata": {},
   "source": [
    "### Converting Speech to Text using `PocketSphinx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf184a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting for ambience...\n",
      "Listening...\n",
      "Recognizing...\n",
      "Recognized Text: hey be free to catch up later today yeah i think so what time were you thinking maybe around five i just have a couple of things to finish up before than five works for me when he wanted me what about that new coffee shop on main street heard a great pastries sounds good to me i've been wanting to try the cappuccino things that will sell housework been all you know this is always were in the middle of the project right now lots of late nights that sounds intense what's the project about it's a new app were developing for managing team tasks it's supposed to help streamline to mediation project management that sounds really useful thing i can dazzle you something like that and my job done yeah we're hoping it'll make a big difference what about you how's everything going for it is in pretty good actually which is turning new rules i'm still getting used to everything that's exciting what's the new role of the canal enlarging courtney in her out on our responsibility as i am enjoying it so we're congratulate so at and step the banks it's been a bit overwhelming but i'm learning a lot that's great here do you have any big projects coming up we're working on a new campaign to follow and lots of planning and strategizing right now are sounds and the guy your hands full definitely and i like staying busy yeah and it keeps things interesting by the way did you share but sarah's promotion now i didn't that's awesome what's her new position she's now the head of the sales department wow that's amazing she's been working so hard and totally deserted i know right we should all go out celebrates the absolute really all texture and see when she's free good idea so have you been watching him to joe's lately yeah i just i watch a menu crime drama everyone's been talking about oh i've heard about that is any good that it's really gripping i couldn't stop watching the plot twists are crazy i might have to check it out and i've been looking for something new to watch definitely do it's one of those shows that keeps you on the edge of your seen awesome my love shows like that what's it called again it's called the silent witness got an all out it's my last thanks for the recommendation no problem so have you had a chance to catch up with anyone else from our old team i actually saw mike last week he's doing well just got back from vacation in hawaii oh that's nice to have always wanted to go to hawaii how was his trap he said it was amazing lots of relaxing on the beach exploring the island's sounds like a dream action plan a trip there sometime the totally shed some light but at least two we should all go together you would be so much find that would be awesome we should seriously think about it definitely let's bring it up only meet sarah good idea so have you picked up any new hobbies lately i've been getting into baking recently it's been a lot of fun trying out new recipes that sounds like ingrained weighed in on wind and one of you being so far mostly cookies and cakes and still learning but it's really satisfying win something turns out well i guess i've been wanting to try taking more to maybe you can give me some tips i'd love to which it haven't eighteen days some time that sounds like a blast let's do it for sure anyway which probably get back to work see a five yeah see then can wake me neither see you later on on an sound the one wound in the month and you know what did\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def speech_to_text():\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print('Adjusting for ambience...')\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=1)  # Adjust based on your ambient noise\n",
    "\n",
    "            print('Listening...')\n",
    "            audio = recognizer.listen(source)  # Wait for 5 seconds for the user to speak\n",
    "            \n",
    "            print('Recognizing...')\n",
    "            text = recognizer.recognize_sphinx(audio)\n",
    "            print(f\"Recognized Text: {text}\")\n",
    "    except sr.WaitTimeoutError:\n",
    "        print(\"No speech was detected in a reasonable amount of time.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from the recognition service; {e}\")\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Unable to recognize any speech.\")\n",
    "\n",
    "speech_to_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a39b7",
   "metadata": {},
   "source": [
    "### Converting Speech to Text using `IBM Watson`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8989ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting for ambience...\n",
      "Listening...\n",
      "Recognizing...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Recognizer.recognize_ibm() missing 1 required positional argument: 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mUnknownValueError:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to recognize any speech.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m speech_to_text()\n",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m, in \u001b[0;36mspeech_to_text\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source)  \u001b[38;5;66;03m# Wait for 5 seconds for the user to speak\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecognizing...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m         text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_ibm(audio)\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecognized Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mWaitTimeoutError:\n",
      "\u001b[0;31mTypeError\u001b[0m: Recognizer.recognize_ibm() missing 1 required positional argument: 'key'"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "#Implementation using PocketSphinx\n",
    "import speech_recognition as sr\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def speech_to_text():\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print('Adjusting for ambience...')\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=1)  # Adjust based on your ambient noise\n",
    "\n",
    "            print('Listening...')\n",
    "            audio = recognizer.listen(source)  # Wait for 5 seconds for the user to speak\n",
    "            \n",
    "            print('Recognizing...')\n",
    "            text = recognizer.recognize_ibm(audio)\n",
    "            print(f\"Recognized Text: {text}\")\n",
    "    except sr.WaitTimeoutError:\n",
    "        print(\"No speech was detected in a reasonable amount of time.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from the recognition service; {e}\")\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Unable to recognize any speech.\")\n",
    "\n",
    "speech_to_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e18b95",
   "metadata": {},
   "source": [
    "### Converting Speech to Text using `Whisper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b65ca3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import warnings\n",
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d045c8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/muddassirkhalidi/Desktop/AIDA Lab/Memoro/MEMORO---II/testing/STT_file.txt\n"
     ]
    }
   ],
   "source": [
    "def speech_to_text(audio):\n",
    "    # Suppress the FP16 warning\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"FP16 is not supported on CPU; using FP32 instead\")\n",
    "\n",
    "    # Load the Whisper model\n",
    "    model = whisper.load_model(\"base\")\n",
    "\n",
    "    # Transcribe the audio file\n",
    "    result = model.transcribe(audio)\n",
    "\n",
    "    with open('STT_file.txt', 'w') as file:\n",
    "        file.write(result[\"text\"])\n",
    "    \n",
    "    return os.getcwd() + '/STT_file.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f53f0ce9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2552295309.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    brew install ffmpeg\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55db7e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Ctrl+C to stop.\n",
      "Recording stopped by user.\n",
      "Audio saved to recorded_until_silence.wav\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def is_silent(data, threshold=0.01):\n",
    "    \"\"\"Return 'True' if below the silence threshold.\"\"\"\n",
    "    return np.abs(data).mean() < threshold\n",
    "\n",
    "def record_until_silence(filename, samplerate=16000, chunk_duration=3, silence_duration=2, threshold=0.01, device=3):\n",
    "    \"\"\"Record audio until silence is detected.\"\"\"\n",
    "    print(\"Recording... Press Ctrl+C to stop.\")\n",
    "    silence_chunk_count = 0\n",
    "    max_silence_chunks = int(silence_duration / chunk_duration)\n",
    "    all_chunks = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Record a chunk of audio\n",
    "            chunk = sd.rec(int(samplerate * chunk_duration), samplerate=samplerate, channels=1, dtype='float32', device=3)\n",
    "            sd.wait()\n",
    "            all_chunks.append(chunk)\n",
    "\n",
    "            # Check if the chunk is silent\n",
    "            if is_silent(chunk, threshold):\n",
    "                silence_chunk_count += 1\n",
    "            else:\n",
    "                silence_chunk_count = 0\n",
    "\n",
    "            # Stop recording if silence is detected for a specified duration\n",
    "            if silence_chunk_count > max_silence_chunks:\n",
    "                print(\"Silence detected. Stopping recording.\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Recording stopped by user.\")\n",
    "\n",
    "    # Concatenate all chunks and save to a file\n",
    "    audio_data = np.concatenate(all_chunks, axis=0)\n",
    "    wav.write(filename, samplerate, (audio_data * 32767).astype(np.int16))\n",
    "    print(f\"Audio saved to {filename}\")\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"recorded_until_silence.wav\"\n",
    "record_until_silence(audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30b4dc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0 iPhone Microphone, Core Audio (1 in, 0 out)\n",
       "< 1 EarPods, Core Audio (0 in, 2 out)\n",
       "> 2 EarPods Microphone, Core Audio (1 in, 0 out)\n",
       "  3 MacBook Pro Microphone, Core Audio (1 in, 0 out)\n",
       "  4 MacBook Pro Speakers, Core Audio (0 in, 2 out)\n",
       "  5 ZoomAudioDevice, Core Audio (2 in, 2 out)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.query_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a5abde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Ctrl+C to stop.\n",
      "Recording Stopped!\n",
      "Audio saved to recorded_until_silence.wav\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "def record_until_silence(output_filename=\"recorded_until_silence.wav\", device_index=3, chunk_size=1024, \n",
    "                         format=pyaudio.paInt16, channels=1, rate=16000, silence_threshold=1000, silence_duration=2):\n",
    "    \"\"\"\n",
    "    Records audio until a period of silence is detected and saves it to a file.\n",
    "\n",
    "    Args:\n",
    "    - output_filename (str): Name of the output WAV file.\n",
    "    - device_index (int): Index of the input audio device.\n",
    "    - chunk_size (int): Number of frames per buffer.\n",
    "    - format: Audio format (e.g., pyaudio.paInt16).\n",
    "    - channels (int): Number of audio channels.\n",
    "    - rate (int): Sampling rate in Hz.\n",
    "    - silence_threshold (int): Amplitude threshold for silence detection.\n",
    "    - silence_duration (int): Duration of silence required to stop recording (in seconds).\n",
    "    \n",
    "    Returns:\n",
    "    - str: The name of the saved audio file.\n",
    "    \"\"\"\n",
    "    # Variables\n",
    "    audio_frames = []\n",
    "    silent_chunks = 0\n",
    "    max_silent_chunks = int(rate / chunk_size * silence_duration)\n",
    "\n",
    "    def is_silent(data, threshold=silence_threshold):\n",
    "        \"\"\"Returns 'True' if below the silence threshold.\"\"\"\n",
    "        return np.max(np.abs(data)) < threshold\n",
    "\n",
    "    def callback(in_data, frame_count, time_info, status):\n",
    "        nonlocal silent_chunks, audio_frames\n",
    "        audio_frames.append(in_data)\n",
    "        audio_data = np.frombuffer(in_data, dtype=np.int16)\n",
    "        if is_silent(audio_data):\n",
    "            silent_chunks += 1\n",
    "        else:\n",
    "            silent_chunks = 0\n",
    "        if silent_chunks > max_silent_chunks:\n",
    "            return (None, pyaudio.paComplete)\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "\n",
    "    # Initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    try:\n",
    "        # Open stream\n",
    "        stream = p.open(format=format,\n",
    "                        channels=channels,\n",
    "                        rate=rate,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=chunk_size,\n",
    "                        stream_callback=callback,\n",
    "                        input_device_index=device_index)\n",
    "\n",
    "        print(\"Please start speaking. Recording... Press Ctrl+C to stop.\")\n",
    "        stream.start_stream()\n",
    "\n",
    "        while stream.is_active():\n",
    "            pass\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"Recording Stopped!\")\n",
    "\n",
    "    finally:\n",
    "        p.terminate()\n",
    "\n",
    "    # Save the recorded audio to a file\n",
    "    with wave.open(output_filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(audio_frames))\n",
    "\n",
    "    print(f\"Audio saved to {output_filename}\")\n",
    "    return output_filename\n",
    "\n",
    "# Example usage\n",
    "recorded_file = record_until_silence()\n",
    "print(f\"Recorded audio file: {recorded_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c3b3298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: iPhone Microphone - 1 channels\n",
      "Device 1: EarPods - 0 channels\n",
      "Device 2: EarPods Microphone - 1 channels\n",
      "Device 3: MacBook Pro Microphone - 1 channels\n",
      "Device 4: MacBook Pro Speakers - 0 channels\n",
      "Device 5: ZoomAudioDevice - 2 channels\n"
     ]
    }
   ],
   "source": [
    "for i in range(p.get_device_count()):\n",
    "    info = p.get_device_info_by_index(i)\n",
    "    print(f\"Device {i}: {info['name']} - {info['maxInputChannels']} channels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9ac72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
